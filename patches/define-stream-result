Bottom: dbe2fa7fde61a7a78146698c81e5a935137615b5
Top:    581a9f45647d396744a0f2bc98195faa23ee2c18
Author: Robert Collins <robertc@robertcollins.net>
Date:   2013-02-15 20:18:54 +1300

This defines a new sort of TestResult, StreamResult.

This is intended to prototype the new API for inclusion upstream.


---

diff --git a/NEWS b/NEWS
index 0c6b7f5..4387557 100644
--- a/NEWS
+++ b/NEWS
@@ -6,6 +6,16 @@ Changes and improvements to testtools_, grouped by release.
 NEXT
 ~~~~
 
+A new sort of TestResult, the StreamResult has been added, as a prototype for
+a revised standard library test result API. The API is not stable yet, though
+we will endeavour to preserve compatibility for early adopters.
+
+Improvements
+------------
+
+* New class ``StreamResult`` which defines the API for the new result type.
+  (Robert Collins)
+
 0.9.29
 ~~~~~~
 
diff --git a/testtools/__init__.py b/testtools/__init__.py
index 707fb55..fa362af 100644
--- a/testtools/__init__.py
+++ b/testtools/__init__.py
@@ -25,6 +25,7 @@ __all__ = [
     'skip',
     'skipIf',
     'skipUnless',
+    'StreamResult',
     'ThreadsafeForwardingResult',
     'try_import',
     'try_imports',
@@ -66,6 +67,7 @@ else:
     from testtools.testresult import (
         ExtendedToOriginalDecorator,
         MultiTestResult,
+        StreamResult,
         Tagger,
         TestByTestResult,
         TestResult,
diff --git a/testtools/testresult/__init__.py b/testtools/testresult/__init__.py
index d37a772..bd1104f 100644
--- a/testtools/testresult/__init__.py
+++ b/testtools/testresult/__init__.py
@@ -5,6 +5,7 @@
 __all__ = [
     'ExtendedToOriginalDecorator',
     'MultiTestResult',
+    'StreamResult',
     'Tagger',
     'TestByTestResult',
     'TestResult',
@@ -16,6 +17,7 @@ __all__ = [
 from testtools.testresult.real import (
     ExtendedToOriginalDecorator,
     MultiTestResult,
+    StreamResult,
     Tagger,
     TestByTestResult,
     TestResult,
diff --git a/testtools/testresult/real.py b/testtools/testresult/real.py
index 7112ab6..c05a002 100644
--- a/testtools/testresult/real.py
+++ b/testtools/testresult/real.py
@@ -6,6 +6,7 @@ __metaclass__ = type
 __all__ = [
     'ExtendedToOriginalDecorator',
     'MultiTestResult',
+    'StreamResult',
     'Tagger',
     'TestResult',
     'TestResultDecorator',
@@ -244,6 +245,127 @@ class TestResult(unittest.TestResult):
         """
 
 
+class StreamResult(object):
+    """A test result for reporting the activity of a test run.
+
+    Typical use
+    -----------
+
+      >>> result = StreamResult()
+      >>> result.startTestRun()
+      >>> try:
+      ...     case.run(result)
+      ... finally:
+      ...     result.stopTestRun()
+
+    The case object will be either a TestCase or a TestSuite, and
+    generally make a sequence of calls like::
+
+      >>> result.status(self.id(), 'inprogress')
+      >>> result.status(self.id(), 'finish')
+
+    General concepts
+    ----------------
+
+    StreamResult is built to process events that are emitted by tests during a
+    test run. The test run may be running concurrently, and even be spread out
+    across multiple machines.
+
+    All events are timestamped to prevent network buffering or scheduling
+    latency causing false timing reports. Timestamps are datetime objects in
+    the UTC timezone.
+
+    A route_code is a unicode string that identifies where a particular test
+    run. This is optional in the API but very useful when multiplexing multiple
+    streams together as it allows identification of interactions between tests
+    that were run on the same hardware or in the same test process. Generally
+    actual tests never need to bother with this - it is added and processed
+    by StreamResult's that do multiplexing / run analysis. route_code's are
+    also used to route stdin back to pdb instances.
+
+    The StreamResult base class does no accounting or processing, rather it
+    just provides an empty implementation of every method, suitable for use
+    as a base class regardless of intent.
+    """
+
+    def startTestRun(self):
+        """Start a test run.
+
+        This will prepare the test result to process results (which might imply
+        connecting to a database or remote machine).
+        """
+
+    def stopTestRun(self):
+        """Stop a test run.
+
+        This informs the result that no more test updates will be received. At
+        this point any test ids that have started and not completed can be
+        considered failed-or-hung.
+        """
+
+    def estimate(self, count, route_code=None, timestamp=None):
+        """Provide an estimated count of tests that will be run.
+
+        This is intended to allow user interfaces that output progress
+        indicators such as "30/120 tests complete". Each estimate given
+        replaces any prior estimate.
+        """
+
+    def file(self, file_name, file_bytes, eof=False, mime_type=None,
+        test_id=None, route_code=None, timestamp=None):
+        """Inform the result about the contents of an attachment.
+        
+        Attachments may be related to a test (by setting test_info to
+        non-None), or are otherwise global to the test run.
+        
+        :param file_name: The name of the attachment. Any unicode string may
+            be used. While there is no semantic value attached to the name
+            of any attachment, the names 'stdout' and 'stderr' and 'traceback'
+            are recommended for use only for output sent to stdout, stderr and
+            tracebacks of exceptions.
+        :param file_bytes: A bytes object containing content for the named
+            file. This can just be a single chunk of the file - emitting
+            another file event with more later.
+        :param eof: This chunk is the last chunk of the file, any additional
+            chunks with the same name should be treated as an error and 
+            discarded.
+        :param mime_type: An optional MIME type for the file. stdout and
+            stderr will generally be "text/plain; charset=utf8". If None,
+            defaults to application/octet-stream.
+        :param test_id: The test that this file is related to. If None, no test
+            is associated with the file.
+        """
+
+    def status(self, test_id, test_status, test_tags=None, runnable=True,
+        route_code=None, timestamp=None):
+        """Inform the result about a test status.
+
+        :param test_id: The test whose status is being reported.
+        :param test_status: One of:
+        * exists - the test exists. This is used when a test is not being
+          executed. Typically this is when querying what tests could be run in
+          a test run (which is useful for selecting tests to run).
+        * inprogress - the test is currently running. Emitted by tests when
+          they start running and at any intermediary point they might choose to
+          indicate their continual operation.
+        * xfail - the test failed but that was expected.
+        * uxsuccess - the test passed but was expected to fail. Like finish,
+          this must be the last event sent for this test.
+        * finish - the test has finished. If no error status had been reported,
+          it can now be considered a success, otherwise it should be considered
+          a failure. This must be the last event sent for this test (including
+          file events).
+        * fail - the test failed (or errored)
+        * skip - the test was selected to run but chose to be skipped. E.g.
+          a test dependency was missing.
+        :param test_tags: Optional set of tags to apply to the test. Tags
+            have no intrinsic meaning - that is up to the test author.
+        :param runnable: Allows status reports to mark that they are for
+            tests which are not able to be explicitly run. For instance,
+            subtests will report themselves as non-runnable.
+        """
+
+
 class MultiTestResult(TestResult):
     """A test result that dispatches to many test results."""
 
diff --git a/testtools/tests/test_testresult.py b/testtools/tests/test_testresult.py
index 64bb743..21f15fd 100644
--- a/testtools/tests/test_testresult.py
+++ b/testtools/tests/test_testresult.py
@@ -21,6 +21,7 @@ from testtools import (
     ExtendedToOriginalDecorator,
     MultiTestResult,
     PlaceHolder,
+    StreamResult,
     Tagger,
     TestCase,
     TestResult,
@@ -446,6 +447,86 @@ class TestTestResultDecoratorContract(TestCase, StartTestRunContract):
         return TestResultDecorator(TestResult())
 
 
+class TestStreamResultContract(object):
+
+    def _make_result(self):
+        raise NotImplementedError(self._make_result)
+
+    def test_startTestRun(self):
+        result = self._make_result()
+        result.startTestRun()
+        result.stopTestRun()
+
+    def test_estimate(self):
+        result = self._make_result()
+        result.startTestRun()
+        self.addCleanup(result.stopTestRun)
+        result.estimate(0)
+        result.estimate(10)
+        result.estimate(5, route_code=_u("1234"))
+        now = datetime.datetime.now(utc)
+        result.estimate(5, route_code=_u("1234"), timestamp=now)
+        result.estimate(5, timestamp=now)
+
+    def test_file(self):
+        result = self._make_result()
+        result.startTestRun()
+        self.addCleanup(result.stopTestRun)
+        now = datetime.datetime.now(utc)
+        inputs = list(dict(
+            eof=True,
+            mime_type="text/plain",
+            route_code=_u("1234"),
+            test_id=_u("foo"),
+            timestamp=now,
+            ).items())
+        param_dicts = self._permute(inputs)
+        for kwargs in param_dicts:
+            result.file(_u("foo"), _b(""), **kwargs)
+            result.file(_u("foo"), _b("bar"), **kwargs)
+
+    def test_status(self):
+        result = self._make_result()
+        result.startTestRun()
+        self.addCleanup(result.stopTestRun)
+        now = datetime.datetime.now(utc)
+        args = [[_u("foo"), s] for s in ['exists', 'inprogress', 'xfail',
+            'uxsuccess', 'finish', 'fail', 'skip']]
+        inputs = list(dict(
+            runnable=False,
+            test_tags=set(['quux']),
+            route_code=_u("1234"),
+            timestamp=now,
+            ).items())
+        param_dicts = self._permute(inputs)
+        for kwargs in param_dicts:
+            for arg in args:
+                result.status(*arg, **kwargs)
+
+    def _permute(self, inputs):
+        param_dicts = [{}]
+        # Build a full set of combinations
+        def permutations(size, inputs):
+            # For each possible start point, return the permutations one size
+            # smaller from the rest of the list combined with that start point.
+            if not size:
+                return [[]]
+            result = []
+            for start in range(len(inputs)-size+1):
+                for permutation in permutations(size-1, inputs[start+1:]):
+                    result.append([inputs[start]] + permutation)
+            return result
+        for size in range(1, len(inputs)+1):
+            param_dicts.extend(dict(p) for p in permutations(size, inputs))
+        return param_dicts
+
+
+class TestBaseStreamResultContract(TestCase, TestStreamResultContract):
+
+    def _make_result(self):
+        return StreamResult()
+
+
 class TestTestResult(TestCase):
     """Tests for 'TestResult'."""
